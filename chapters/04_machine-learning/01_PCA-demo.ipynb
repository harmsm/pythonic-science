{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xy = np.random.multivariate_normal([0,0], [[10,7],[7,10]],1000)\n",
    "plt.plot(xy[:,0],xy[:,1],\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a Principle Component Analysis (PCA) object\n",
    "\n",
    "What is `n_components`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`num_components` is the number of axes on which you spread the data out.  You can only have as many components as you have axes (2 in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fit the axes\n",
    "\n",
    "What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xy_pca = pca.fit(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Does the PCA, finding the primary axes of variation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xy[:,0],xy[:,1],\"o\")\n",
    "\n",
    "scalar = xy_pca.explained_variance_[0]\n",
    "plt.plot([0,xy_pca.components_[0,0]*scalar/2],[0,xy_pca.components_[0,1]*scalar/2],color=\"red\")\n",
    "plt.plot([0,-xy_pca.components_[0,0]*scalar/2],[0,-xy_pca.components_[0,1]*scalar/2],color=\"red\")\n",
    "\n",
    "scalar = xy_pca.explained_variance_[1]\n",
    "plt.plot([0,xy_pca.components_[1,0]*scalar/2],[0,xy_pca.components_[1,1]*scalar/2],color=\"yellow\")\n",
    "plt.plot([0,-xy_pca.components_[1,0]*scalar/2],[0,-xy_pca.components_[1,1]*scalar/2],color=\"yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What does the following do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xy_trans = xy_pca.transform(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Transforms `x` and `y` onto the PCA axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(xy[:,0],xy[:,1],\"o\")\n",
    "ax[0].set_xlabel(\"x\")\n",
    "ax[0].set_ylabel(\"y\")\n",
    "ax[0].set_xlim((-15,15)); ax[0].set_ylim((-15,15))\n",
    "ax[1].plot(xy_trans[:,0],xy_trans[:,1],\"o\")\n",
    "ax[1].set_xlabel(\"PCA1\")\n",
    "ax[1].set_ylabel(\"PCA2\")\n",
    "ax[1].set_xlim((-15,15)); ax[1].set_ylim((-15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What does the following do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Variation explained:\")\n",
    "print(\"First component: {:.3f}\".format(xy_pca.explained_variance_ratio_[0]))\n",
    "print(\"Second component: {:.3f}\".format(xy_pca.explained_variance_ratio_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Describes how much variation each PCA axis captures.  \n",
    "\n",
    "Informally: if you only included the first component in a predictive model, the $R^{2}$ between you prediction and reality would be 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some helper code, which takes an xy_pair and does all of the steps above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def pca_wrapper(xy_pairs):\n",
    "    \"\"\"\n",
    "    Take an array of x/y data and perform a principle component analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "    \n",
    "    ax[0].plot(xy_pairs[:,0],xy_pairs[:,1],\"o\")\n",
    "    ax[0].set_xlim((-18,18))\n",
    "    ax[0].set_ylim((-18,18))\n",
    "    ax[0].set_title(\"raw x,y data\")\n",
    "    ax[0].set_xlabel(\"x\")\n",
    "    ax[0].set_ylabel(\"y\")\n",
    "\n",
    "    # Perform the PCA fit\n",
    "    pca = PCA(n_components=2)\n",
    "    z = pca.fit(xy_pairs)\n",
    "    \n",
    "    # Transforom the data onto the new PCA axes\n",
    "    new_xy_pairs = z.transform(xy_pairs)\n",
    "    \n",
    "    # Plot the PCA data\n",
    "    ax[1].plot(new_xy_pairs[:,0],new_xy_pairs[:,1],\"o\")\n",
    "    ax[1].set_title(\"PCA transformed data\")\n",
    "    ax[1].set_xlim((-18,18))\n",
    "    ax[1].set_ylim((-18,18))\n",
    "    ax[1].set_xlabel(\"PCA1\")\n",
    "    ax[1].set_ylabel(\"PCA2\")\n",
    "\n",
    "    print(\"Variation explained:\")\n",
    "    print(\"First component: {:.3f}\".format(pca.explained_variance_ratio_[0]))\n",
    "    print(\"Second component: {:.3f}\".format(pca.explained_variance_ratio_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does fraction variation relate to skew in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d1 = np.random.multivariate_normal([0,0], [[10,1],[1,10]],1000) \n",
    "pca_wrapper(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d2 = np.random.multivariate_normal([0,0], [[10,5],[5,10]],1000)\n",
    "pca_wrapper(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d3 = np.random.multivariate_normal([0,0], [[10,9],[9,10]],1000)\n",
    "pca_wrapper(d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The stronger the covariation between parameters, the more readily the PCA can reduce dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using PCA to try to classify things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The \"Iris\" dataset\n",
    "<img style=\"margin:auto\" align=\"center\" src=\"https://www.math.umd.edu/~petersd/666/html/iris_with_labels.jpg\" />\n",
    "\n",
    "+ Three species of iris\n",
    "+ Four properties measured for many representatives from each species\n",
    "+ Properties are: sepal length, sepal width, petal length, petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "obs = iris.data\n",
    "species = iris.target\n",
    "\n",
    "mean = obs.mean(axis=0)\n",
    "std = obs.std(axis=0)\n",
    "obs = (obs - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The mean, standard deviation business normalizes the data so the values are all on the same scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_slice(obs_r,axis_i,axis_j):\n",
    "    \"\"\"\n",
    "    Define a helper function.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(obs_r[species == 0,axis_i],obs_r[species == 0,axis_j],\"o\",color='navy')\n",
    "    plt.plot(obs_r[species == 1,axis_i],obs_r[species == 1,axis_j],\"o\",color='turquoise')\n",
    "    plt.plot(obs_r[species == 2,axis_i],obs_r[species == 2,axis_j],\"o\",color='darkorange')\n",
    "    plt.xlabel(axis_i)\n",
    "    plt.ylabel(axis_j)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Species separate on some axes, but not all axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plot_slice(obs,axis_i=0,axis_j=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "obs_pca = pca.fit(obs)\n",
    "obs_trans = obs_pca.transform(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is different about PCA axes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plot_slice(obs_trans,axis_i=0,axis_j=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All of that separating power is jammed into the first axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantify this with explained varience ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for r in obs_pca.explained_variance_ratio_:\n",
    "    print(\"{:.3f}\".format(r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "+ PCA is a way to spread data out on \"natural\" axes\n",
    "+ Clusters in PCA space can be used to classify things\n",
    "+ Axes may be hard to interpret directly"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
